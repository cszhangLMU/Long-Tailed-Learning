


**A Systematic Review on Long-Tailed Learning**

Chongsheng Zhang, George Almpanidis, Gaojuan Fan, Binquan Deng, Yanbo Zhang, Ji Liu, Aouaidjia Kamel, Paolo Soda, Jo√£o Gama. A Systematic Review on Long-Tailed Learning.  IEEE Transactions on Neural Networks and Learning Systems, 26(8):13670--13690, 2025.  [PDF](https://github.com/cszhangLMU/Long-Tailed-Learning/blob/main/A_Systematic_Review_on_Long-Tailed_Learning%20%20IEEE%20TNNLS.pdf).

**Abstract**:

Long-tailed data are a special type of multiclass imbalanced data with a very large amount of minority/tail classes that have a very significant combined influence. Long-tailed learning (LTL) aims to build high-performance models on datasets with long-tailed distributions that can identify all the classes with high accuracy, in particular the minority/tail classes. It is a cutting-edge research direction that has attracted a remarkable amount of research effort in the past few years. In this article, we present a comprehensive survey of the latest advances in long-tailed visual learning. We first propose a new taxonomy for LTL, which consists of eight different dimensions, including data balancing, neural architecture, feature enrichment, logits adjustment, loss function, bells and whistles, network optimization, and posthoc processing techniques. Based on our proposed taxonomy, we present a systematic review of LTL methods, discussing their commonalities and alignable differences. We also analyze the differences between imbalance learning and LTL. Finally, we discuss prospects and future directions in this field.

bibtex

@ARTICLE{LTLSurvey2025,

  author={Zhang, Chongsheng and Almpanidis, George and Fan, Gaojuan and Deng, Binquan and Zhang, Yanbo and Liu, Ji and Kamel, Aouaidjia and Soda, Paolo and Gama, Jo{\~{a}}o},
  
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  
  title={A Systematic Review on Long-Tailed Learning}, 
  
  year={2025},
  
  volume={36},
  
  number={8},
  
  pages={13670-13690},
  
  }
